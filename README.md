# PR-SAM: Patient-Specific Prior-Refined Prompting of a Frozen SAM for Quality-Robust CBCT Segmentation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 1.9+](https://img.shields.io/badge/pytorch-1.9+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Official implementation of **PR-SAM** (Prior-Refined SAM), a novel framework for quality-robust CBCT segmentation in online adaptive radiotherapy.

<p align="center">
  <img src="results/figures/two_patients_comparison.png" width="100%" alt="Segmentation Comparison">
</p>

## ğŸ“‹ Abstract

Online adaptive radiotherapy (ART) requires fast, reliable segmentation of same-day CBCT despite artifacts that degrade image quality. We propose **PR-SAM**, a planning-CT guided approach that injects patient-specific anatomical priors into a frozen Segment Anything Model (SAM) to achieve robust CBCT segmentation without backbone fine-tuning.

**Key Results:**
- **Dice: 0.9611** | **HD95: 2.46 mm** (overall performance)
- **Quality-invariant**: Dice range 0.0005 across all quality tiers
- **+4.9% Dice** improvement over best baseline (U-Net)
- **-75.6% HD95** reduction compared to best baseline

<p align="center">
  <img src="results/figures/quality_robustness_multi_metrics.png" width="100%" alt="Quality Robustness">
</p>

## ğŸ—ï¸ Architecture

PR-SAM consists of four key components:

1. **Prior Encoder** (`N_prior`): Converts registered pCT masks into multi-channel representations (binary, signed-distance, boundary maps)
2. **Adaptive Correction Network** (`N_correct`): Learns feature-level residual refinement
3. **CBCT Domain Adapter**: Preserves domain-specific details from CBCT images
4. **Dual-Branch Decoding**: Combines prior-guided and correction branches for robust inference

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    PR-SAM Architecture                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    
    pCT Mask â”€â”€â–º Prior Encoder â”€â”€â–º Prior Features â”€â”€â”¬â”€â”€â–º Prior Branch â”€â”€â”
                    (0.37M)              â”‚          â”‚                    â”‚
                                         â”‚          â–¼                    â”‚
                                         â””â”€â”€â–º Correction Network â”€â”€â–ºâ”€â”€â”€â”€â”€â”¼â”€â”€â–º Fusion â”€â”€â–º Output
                                              (1.84M)                    â”‚
    CBCT â”€â”€â”€â”€â–º SAM Encoder â”€â”€â–º CBCT Features â”€â”€â–º CBCT Adapter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               (frozen 93.7M)                    (0.07M)
```

## ğŸ“ Project Structure

```
PR-SAM/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ proposed/
â”‚   â”‚   â””â”€â”€ pgrsam/
â”‚   â”‚       â”œâ”€â”€ pgr_sam_model.py      # Main PR-SAM model
â”‚   â”‚       â”œâ”€â”€ pct_prior_encoder.py  # Prior encoder network
â”‚   â”‚       â”œâ”€â”€ correction_network.py # Adaptive correction network
â”‚   â”‚       â””â”€â”€ ablation_models.py    # Ablation study variants
â”‚   â””â”€â”€ baselines/
â”‚       â”œâ”€â”€ unet/                     # U-Net
â”‚       â”œâ”€â”€ attention_unet/           # Attention U-Net
â”‚       â”œâ”€â”€ nnunet/                   # nnU-Net
â”‚       â”œâ”€â”€ resunet/                  # ResU-Net
â”‚       â”œâ”€â”€ vnet/                     # V-Net
â”‚       â””â”€â”€ polar_unet/               # PolarUNet
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.py                    # Base dataset class
â”‚   â””â”€â”€ multi_quality_dataset.py      # Multi-quality CBCT dataset
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ proposed_models.yaml          # PR-SAM configuration
â”‚   â”œâ”€â”€ baseline_models.yaml          # Baseline configurations
â”‚   â””â”€â”€ ablation_study.yaml           # Ablation study configs
â”œâ”€â”€ segment_anything_medsam/          # SAM backbone
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py                    # Evaluation metrics (Dice, IoU, HD95)
â”‚   â””â”€â”€ data_preprocessing.py         # Data preprocessing utilities
â”œâ”€â”€ train_pgrsam.py                   # Training script for PR-SAM
â”œâ”€â”€ train.py                          # Training script for baselines
â”œâ”€â”€ evaluate_pgrsam.py                # Evaluation script
â””â”€â”€ preprocess_dataset.py             # Data preprocessing
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/PR-SAM.git
cd PR-SAM

# Create conda environment
conda create -n prsam python=3.9
conda activate prsam

# Install dependencies
pip install -r requirements.txt
```

### Download Pretrained Weights

Download the SAM ViT-B checkpoint:
```bash
mkdir checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O checkpoints/sam_vit_b_01ec64.pth
```

### Data Preparation

1. Download the [LiTS dataset](https://competitions.codalab.org/competitions/17094)
2. Run preprocessing to generate multi-quality synthetic CBCT:

```bash
python preprocess_dataset.py --input_dir /path/to/LiTS --output_dir datasets/LiTS-preprocessed
```

This generates 5 CBCT quality tiers (Q32, Q64, Q128, Q256, Q490 projections).

### Training

**Train PR-SAM:**
```bash
python train_pgrsam.py --config configs/proposed_models.yaml
```

**Train Baselines:**
```bash
python train.py --model unet
python train.py --model attention_unet
python train.py --model nnunet
```

### Evaluation

```bash
python evaluate_pgrsam.py --checkpoint results/proposed/prsam/best_model.pth
```

## ğŸ“Š Results

### Quantitative Results (Test Set)

| Model | Dice â†‘ | IoU â†‘ | HD95 (mm) â†“ | Params |
|-------|--------|-------|-------------|--------|
| U-Net | 0.9165 | 0.8564 | 10.10 | 31.0M |
| Attention U-Net | 0.9092 | 0.8461 | 13.53 | 34.9M |
| nnU-Net | 0.8957 | 0.8284 | 11.14 | 31.2M |
| ResU-Net | 0.8871 | 0.8153 | 10.62 | 32.5M |
| V-Net | 0.9072 | 0.8446 | 8.04 | 45.6M |
| PolarUNet | 0.8658 | 0.7875 | 16.42 | 24.9M |
| **PR-SAM (Ours)** | **0.9611** | **0.9271** | **2.46** | **96.0M (2.3M trainable)** |

### Quality Robustness

| Quality | PR-SAM Dice | Best Baseline Dice | Improvement |
|---------|-------------|-------------------|-------------|
| Q32 (lowest) | 0.9611 | 0.8554 (U-Net) | +12.4% |
| Q64 | 0.9610 | 0.8863 (U-Net) | +8.4% |
| Q128 | 0.9609 | 0.9108 (U-Net) | +5.5% |
| Q256 | 0.9612 | 0.9258 (U-Net) | +3.8% |
| Q490 (highest) | 0.9614 | 0.9337 (V-Net) | +3.0% |

## ğŸ”¬ Ablation Study

| Configuration | Dice | HD95 (mm) |
|--------------|------|-----------|
| Full PR-SAM | 0.9611 | 2.46 |
| w/o Correction Network | 0.9528 | 3.21 |
| w/o Prior Encoder | 0.9445 | 4.15 |
| w/o CBCT Adapter | 0.9567 | 2.89 |
| Binary Prior Only | 0.9523 | 3.18 |
| Distance Prior Only | 0.9501 | 3.45 |

## ğŸ’» Computational Efficiency

| Model | Trainable Params | Total Params | Inference Time |
|-------|-----------------|--------------|----------------|
| U-Net | 31.0M | 31.0M | 12 ms |
| PR-SAM | 2.28M (2.4%) | 96.0M | 42 ms |

## ğŸ“ Citation

If you find this work useful, please cite:

```bibtex
@article{prsam2024,
  title={PR-SAM: Patient-Specific Prior-Refined Prompting of a Frozen SAM for Quality-Robust CBCT Segmentation in Online Adaptive Radiotherapy},
  author={},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2024}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything) by Meta AI
- [LiTS Dataset](https://competitions.codalab.org/competitions/17094) for liver tumor segmentation benchmark
- PyTorch and the open-source community

## ğŸ“§ Contact

For questions or collaborations, please open an issue or contact [your-email@example.com].

